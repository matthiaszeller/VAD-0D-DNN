{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipypublish import nb_setup\n",
    "# https://stackoverflow.com/a/39566040/11552622\n",
    "rcparams = {\n",
    "    'axes.titlesize':13,\n",
    "    'axes.labelsize':9,\n",
    "    'xtick.labelsize':8,\n",
    "    'ytick.labelsize':8\n",
    "}\n",
    "plt = nb_setup.setup_matplotlib(rcparams=rcparams)\n",
    "pd = nb_setup.setup_pandas()\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ipub": {
     "ignore": true
    }
   },
   "source": [
    "# Load data, setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = pd.read_csv('data/dnn_stats.csv')\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dnn_stats_data.bin', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistics(data, configs, rpms, display_values, fun_descr):\n",
    "    nrow = len(configs)\n",
    "    ncol = len(rpms)\n",
    "    fig, axgrid = plt.subplots(nrow, ncol, figsize=(2.8*ncol + .5, 1.75*nrow + .5),\n",
    "                              sharey='row', sharex='col')\n",
    "    \n",
    "    for i, (axes, config) in enumerate(zip(axgrid, configs)):\n",
    "        # Plot data\n",
    "        last_val = {val: [] for val in display_values}\n",
    "        for rpm, a in zip(rpms, axes):\n",
    "            key = (rpm, ) + config\n",
    "            a.plot(data[key]['loss'], label='loss', lw=.5)\n",
    "            a.plot(data[key]['val_loss'], label='val loss', lw=.5)\n",
    "            # Extract last values\n",
    "            for val in display_values:\n",
    "                last_val[val].append(data[key][val][-1])\n",
    "            #last_val['loss'].append(data[key]['loss'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # X-Label management\n",
    "        # First row vs not\n",
    "        if i == 0:\n",
    "            axes[0].legend()\n",
    "            for rpm, a in zip(rpms, axes): a.set_title(f'{rpm} RPM')\n",
    "        # Last row vs not\n",
    "        #if i < nrow-1:\n",
    "        #    for a in axes: a.set_xticklabels([])\n",
    "        #else:\n",
    "        #    for a in axes: a.set_xlabel('Epochs')\n",
    "        \n",
    "        # Y-label management\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        #axes[-1].yaxis.set_label_position('right')\n",
    "        #axes[-1].yaxis.tick_right()\n",
    "        \n",
    "        #fig.align_ylabels(axes)\n",
    "        \n",
    "        # Text management - Compute mean values, display\n",
    "        text = '\\n'.join([\n",
    "            'mean ' + val.replace(\"_\", \" \") + ': ' + \\\n",
    "            '{:.3}'.format(np.mean(last_val[val]))\n",
    "            for val in display_values\n",
    "        ])\n",
    "        text = '\\\\textbf{'+fun_descr(config)+'}' + '\\n' + text\n",
    "        axes[0].text(-1.5, .5, text, transform=axes[0].transAxes, \n",
    "                     verticalalignment='center')\n",
    "    \n",
    "    for a in axgrid[-1]: a.set_xlabel('Epochs')\n",
    "    # General plot properties\n",
    "    fig.subplots_adjust(wspace=.05, hspace=.05)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2config(df):\n",
    "    return [\n",
    "        (l, n, c) for l,n,c in zip(df.hlayers, df.neurons, df.aks)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ipub": {
     "ignore": true
    }
   },
   "source": [
    "## Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [(2, 64, 40),\n",
    "           (4, 32, 40),\n",
    "           (2, 32, 40)]\n",
    "fun_descr = lambda config: f'{config[0]} layers, {config[1]} neurons'\n",
    "plot_statistics(data, configs, [4000, 5000, 6000], \n",
    "                ['loss', 'val_loss', 'mae', 'val_mae'], fun_descr)\n",
    "#plt.savefig('figs/dnn_statistics_sorted_40aks.eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best architectures - 50 aks\n",
    "\n",
    "1. We have 312 configurations in total, determined by the number of hidden layers (L), the number of neurons (N), the number of Fourier coefficients (C) and the pump speed (RPM). \n",
    "\n",
    "1. A DNN was trained for each configuration, losses were extracted\n",
    "\n",
    "1. We computed the mean values among the different pump speeds\n",
    "\n",
    "1. This yields 104 DNN architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ipub": {
     "table": {
      "caption": "Portion of the table containing statistics on DNN architectures, values are averaged over three configurations (4000, 5000 and 6000 RPMs)."
     }
    }
   },
   "outputs": [],
   "source": [
    "avg.iloc[np.r_[0:5, -5:0], :].rename(columns={col: col.replace('_', ' ') for col in avg.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then constrain the number of Fourier coefficients, according to the value that allows a physiologically meaningful reconstruction of the DNN input signals. We choose $K=50$ and we sort the architectures by the validation MAE (mean absolute error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = avg[avg.aks == 50].copy()\n",
    "sub.sort_values('val_mae', inplace=True, ignore_index=True)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ipub": {
     "table": {
      "caption": "First 7 best DNN architectures having the number of Fourier coefficients constrained to $K = 50$. Best refers to minimizing the validation mean absolute error (`val_mae`)."
     }
    }
   },
   "outputs": [],
   "source": [
    "sub.head(7).rename(columns={col: col.replace('_', ' ') for col in avg.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = df2config(sub.head(7))\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ipub": {
     "figure": {
      "caption": "Losses of the first 7 best DNN architectures with $K = 50$, sorted by the validation MAE, according to the table above."
     }
    }
   },
   "outputs": [],
   "source": [
    "fun_descr = lambda config: f'L={config[0]}, N={config[1]}, C={config[2]}'\n",
    "plot_statistics(data, conf, [4000, 5000, 6000], \n",
    "                ['loss', 'val_loss', 'mae', 'val_mae'], fun_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_comparison(df):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(8, 6), sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "    hlayers = sorted(df.hlayers.unique())\n",
    "    \n",
    "    for L, ax in zip(hlayers, axes):\n",
    "        tmp = df[df.hlayers == L].sort_values('neurons')\n",
    "        ax.plot(tmp.neurons, tmp.val_loss, '-o', label='val loss')\n",
    "        ax.plot(tmp.neurons, tmp.loss, '--o', label='loss')\n",
    "        ax.set_title(fr'$L = {L}$')\n",
    "    \n",
    "    axes[0].set_xticks(sorted(df.neurons.unique()))\n",
    "    axes[-1].set_xlabel('Neurons')\n",
    "    axes[-2].set_xlabel('Neurons')\n",
    "    for a in axes[0::2]:\n",
    "        a.set_ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplots_adjust(hspace=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ipub": {
     "figure": {
      "caption": "Loss and validation loss in function of the number of neurons, for  different number of hidden layers ($L$), all with the number of coefficients set to $K = 50$."
     }
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_comparison(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_comparison2(df):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(8, 8), sharex=True)\n",
    "    \n",
    "    hlayers = df.hlayers.unique()\n",
    "    for l in hlayers:\n",
    "        tmp = df[df.hlayers == l].sort_values('neurons')\n",
    "        ax[0].plot(tmp.neurons, tmp.val_loss, '-o')\n",
    "        ax[0].set_ylabel('Validation loss')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_comparison2(sub)"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "figure": {
    "placement": "H"
   },
   "table": {
    "placement": "H"
   },
   "titlepage": {
    "title": "DNN Statistics"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
